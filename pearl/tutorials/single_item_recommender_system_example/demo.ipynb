{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Installation\n",
    "If you haven't installed Pearl, please make sure you install Pearl with the following cell. Otherwise, you can skip the cell below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%pip uninstall Pearl -y\n",
    "%rm -rf Pearl\n",
    "!git clone https://github.com/facebookresearch/Pearl.git\n",
    "%cd Pearl\n",
    "%pip install .\n",
    "%cd .."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Modules"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pearl.neural_networks.common.value_networks import EnsembleQValueNetwork\n",
    "from pearl.replay_buffers.sequential_decision_making.bootstrap_replay_buffer import BootstrapReplayBuffer\n",
    "from pearl.policy_learners.sequential_decision_making.bootstrapped_dqn import BootstrappedDQN\n",
    "from pearl.utils.functional_utils.experimentation.set_seed import set_seed\n",
    "from pearl.action_representation_modules.identity_action_representation_module import IdentityActionRepresentationModule\n",
    "from pearl.history_summarization_modules.lstm_history_summarization_module import LSTMHistorySummarizationModule\n",
    "from pearl.policy_learners.sequential_decision_making.deep_q_learning import DeepQLearning\n",
    "from pearl.replay_buffers.sequential_decision_making.fifo_off_policy_replay_buffer import FIFOOffPolicyReplayBuffer\n",
    "from pearl.utils.functional_utils.train_and_eval.online_learning import online_learning\n",
    "from pearl.pearl_agent import PearlAgent\n",
    "from pearl.tutorials.single_item_recommender_system_example.env_model import SequenceClassificationModel\n",
    "from pearl.tutorials.single_item_recommender_system_example.env import RecEnv\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "set_seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T16:10:58.598625900Z",
     "start_time": "2024-01-18T16:10:55.114301800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Environment\n",
    "This environment's underlying model is trained using the MIND dataset (Wu et al. 2020).\n",
    "\n",
    "Each data point:\n",
    "- A history of impressions clicked by a user\n",
    "- Each impression is represented by an 100-dim vector\n",
    "- A list of impressions and whether or not they are clicked\n",
    "\n",
    "The environment is constructed with the following setup. Note that this example is a contrived example to illustrate Pearl's usage, agent modularity and a subset of features. Not to represent a real-world environment or problem.  \n",
    "- State: a history of impressions by a user (note that we used the history of impressions of instead of clicked impressions to speed up learning in this example. Interested Pearl users can change it to history of clicked impressions with much longer episode length and samples to run the following experiments.)\n",
    "- Dynamic action space: two randomly picked impressions\n",
    "- Action: one of the two impressions\n",
    "- Reward: click\n",
    "- Reset every 20 steps.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# load environment\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SequenceClassificationModel(100).to(device)\n",
    "model.load_state_dict(torch.load(\"env_model_state_dict.pt\"))\n",
    "actions = torch.load(\"news_embedding_small.pt\")\n",
    "env = RecEnv(list(actions.values())[:100], model)\n",
    "observation, action_space = env.reset()\n",
    "\n",
    "# experiment code\n",
    "number_of_steps = 100000\n",
    "record_period = 400"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T16:11:03.619884400Z",
     "start_time": "2024-01-18T16:11:02.997232800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|## Vanilla DQN Agent\n",
    "Able to handle dynamic action space but not able to handle partial observability and sparse reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kulkpFAvnOQx",
    "ExecuteTime": {
     "end_time": "2024-01-18T16:21:32.929161600Z",
     "start_time": "2024-01-18T16:11:25.932661300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5, step 100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 10, step 200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 15, step 300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 20, step 400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 25, step 500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 30, step 600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 35, step 700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 40, step 800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 45, step 900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 50, step 1000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 55, step 1100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 60, step 1200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 65, step 1300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 70, step 1400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 75, step 1500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 80, step 1600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 85, step 1700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 90, step 1800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 95, step 1900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 100, step 2000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 105, step 2100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 110, step 2200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 115, step 2300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 120, step 2400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 125, step 2500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 130, step 2600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 135, step 2700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 140, step 2800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 145, step 2900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 150, step 3000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 155, step 3100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 160, step 3200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 165, step 3300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 170, step 3400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 175, step 3500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 180, step 3600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 185, step 3700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 190, step 3800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 195, step 3900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 200, step 4000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 205, step 4100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 210, step 4200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 215, step 4300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 220, step 4400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 225, step 4500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 230, step 4600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 235, step 4700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 240, step 4800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 245, step 4900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 250, step 5000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 255, step 5100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 260, step 5200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 265, step 5300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 270, step 5400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 275, step 5500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 280, step 5600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 285, step 5700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 290, step 5800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 295, step 5900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 300, step 6000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 305, step 6100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 310, step 6200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 315, step 6300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 320, step 6400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 325, step 6500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 330, step 6600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 335, step 6700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 340, step 6800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 345, step 6900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 350, step 7000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 355, step 7100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 360, step 7200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 365, step 7300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 370, step 7400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 375, step 7500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 380, step 7600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 385, step 7700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 390, step 7800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 395, step 7900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 400, step 8000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 405, step 8100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 410, step 8200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 415, step 8300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 420, step 8400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 425, step 8500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 430, step 8600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 435, step 8700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 440, step 8800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 445, step 8900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 450, step 9000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 455, step 9100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 460, step 9200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 465, step 9300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 470, step 9400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 475, step 9500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 480, step 9600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 485, step 9700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 490, step 9800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 495, step 9900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 500, step 10000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 505, step 10100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 510, step 10200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 515, step 10300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 520, step 10400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 525, step 10500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 530, step 10600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 535, step 10700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 540, step 10800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 545, step 10900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 550, step 11000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 555, step 11100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 560, step 11200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 565, step 11300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 570, step 11400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 575, step 11500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 580, step 11600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 585, step 11700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 590, step 11800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 595, step 11900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 600, step 12000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 605, step 12100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 610, step 12200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 615, step 12300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 620, step 12400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 625, step 12500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 630, step 12600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 635, step 12700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 640, step 12800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 645, step 12900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 650, step 13000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 655, step 13100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 660, step 13200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 665, step 13300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 670, step 13400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 675, step 13500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 680, step 13600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 685, step 13700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 690, step 13800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 695, step 13900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 700, step 14000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 705, step 14100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 710, step 14200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 715, step 14300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 720, step 14400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 725, step 14500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 730, step 14600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 735, step 14700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 740, step 14800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 745, step 14900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 750, step 15000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 755, step 15100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 760, step 15200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 765, step 15300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 770, step 15400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 775, step 15500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 780, step 15600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 785, step 15700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 790, step 15800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 795, step 15900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 800, step 16000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 805, step 16100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 810, step 16200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 815, step 16300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 820, step 16400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 825, step 16500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 830, step 16600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 835, step 16700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 840, step 16800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 845, step 16900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 850, step 17000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 855, step 17100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 860, step 17200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 865, step 17300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 870, step 17400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 875, step 17500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 880, step 17600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 885, step 17700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 890, step 17800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 895, step 17900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 900, step 18000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 905, step 18100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 910, step 18200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 915, step 18300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 920, step 18400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 925, step 18500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 930, step 18600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 935, step 18700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 940, step 18800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 945, step 18900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 950, step 19000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 955, step 19100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 960, step 19200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 965, step 19300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 970, step 19400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 975, step 19500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 980, step 19600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 985, step 19700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 990, step 19800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 995, step 19900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1000, step 20000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1005, step 20100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1010, step 20200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 1015, step 20300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1020, step 20400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1025, step 20500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1030, step 20600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1035, step 20700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1040, step 20800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1045, step 20900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1050, step 21000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1055, step 21100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1060, step 21200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1065, step 21300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1070, step 21400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1075, step 21500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1080, step 21600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1085, step 21700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1090, step 21800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1095, step 21900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1100, step 22000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1105, step 22100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1110, step 22200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1115, step 22300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1120, step 22400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1125, step 22500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1130, step 22600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1135, step 22700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1140, step 22800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1145, step 22900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1150, step 23000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1155, step 23100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1160, step 23200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1165, step 23300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1170, step 23400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1175, step 23500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1180, step 23600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1185, step 23700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1190, step 23800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1195, step 23900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1200, step 24000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1205, step 24100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1210, step 24200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1215, step 24300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1220, step 24400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1225, step 24500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1230, step 24600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1235, step 24700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1240, step 24800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1245, step 24900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1250, step 25000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1255, step 25100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1260, step 25200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1265, step 25300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1270, step 25400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1275, step 25500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1280, step 25600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1285, step 25700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1290, step 25800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1295, step 25900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1300, step 26000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1305, step 26100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1310, step 26200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1315, step 26300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1320, step 26400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1325, step 26500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1330, step 26600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1335, step 26700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1340, step 26800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1345, step 26900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1350, step 27000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1355, step 27100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1360, step 27200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1365, step 27300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1370, step 27400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1375, step 27500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1380, step 27600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1385, step 27700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1390, step 27800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1395, step 27900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1400, step 28000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1405, step 28100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1410, step 28200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1415, step 28300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1420, step 28400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1425, step 28500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1430, step 28600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1435, step 28700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1440, step 28800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1445, step 28900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1450, step 29000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1455, step 29100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1460, step 29200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1465, step 29300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1470, step 29400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1475, step 29500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1480, step 29600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1485, step 29700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1490, step 29800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1495, step 29900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1500, step 30000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1505, step 30100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1510, step 30200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1515, step 30300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1520, step 30400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1525, step 30500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1530, step 30600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1535, step 30700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1540, step 30800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1545, step 30900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1550, step 31000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1555, step 31100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1560, step 31200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1565, step 31300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1570, step 31400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1575, step 31500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1580, step 31600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1585, step 31700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1590, step 31800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1595, step 31900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1600, step 32000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1605, step 32100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1610, step 32200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1615, step 32300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1620, step 32400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1625, step 32500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1630, step 32600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1635, step 32700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1640, step 32800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1645, step 32900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1650, step 33000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1655, step 33100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1660, step 33200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1665, step 33300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1670, step 33400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1675, step 33500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1680, step 33600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1685, step 33700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1690, step 33800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1695, step 33900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1700, step 34000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1705, step 34100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1710, step 34200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1715, step 34300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1720, step 34400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1725, step 34500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1730, step 34600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1735, step 34700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1740, step 34800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1745, step 34900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1750, step 35000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1755, step 35100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1760, step 35200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1765, step 35300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1770, step 35400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1775, step 35500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1780, step 35600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1785, step 35700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1790, step 35800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1795, step 35900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1800, step 36000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1805, step 36100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1810, step 36200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1815, step 36300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1820, step 36400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1825, step 36500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1830, step 36600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1835, step 36700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1840, step 36800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1845, step 36900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1850, step 37000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1855, step 37100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1860, step 37200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1865, step 37300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1870, step 37400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1875, step 37500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1880, step 37600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1885, step 37700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1890, step 37800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 7.0\n",
      "episode 1895, step 37900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1900, step 38000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1905, step 38100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1910, step 38200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1915, step 38300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1920, step 38400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1925, step 38500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1930, step 38600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1935, step 38700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1940, step 38800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1945, step 38900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1950, step 39000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1955, step 39100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1960, step 39200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1965, step 39300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1970, step 39400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1975, step 39500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1980, step 39600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1985, step 39700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1990, step 39800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1995, step 39900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2000, step 40000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2005, step 40100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2010, step 40200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2015, step 40300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2020, step 40400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2025, step 40500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2030, step 40600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2035, step 40700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2040, step 40800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2045, step 40900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2050, step 41000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2055, step 41100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2060, step 41200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2065, step 41300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2070, step 41400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2075, step 41500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2080, step 41600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2085, step 41700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2090, step 41800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2095, step 41900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2100, step 42000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2105, step 42100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2110, step 42200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2115, step 42300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2120, step 42400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2125, step 42500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2130, step 42600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2135, step 42700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2140, step 42800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2145, step 42900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2150, step 43000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2155, step 43100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2160, step 43200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2165, step 43300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2170, step 43400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2175, step 43500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2180, step 43600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2185, step 43700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2190, step 43800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2195, step 43900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2200, step 44000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2205, step 44100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2210, step 44200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2215, step 44300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2220, step 44400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2225, step 44500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2230, step 44600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2235, step 44700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2240, step 44800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2245, step 44900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2250, step 45000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2255, step 45100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2260, step 45200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2265, step 45300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2270, step 45400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2275, step 45500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2280, step 45600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2285, step 45700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2290, step 45800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2295, step 45900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2300, step 46000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2305, step 46100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2310, step 46200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2315, step 46300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2320, step 46400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2325, step 46500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2330, step 46600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2335, step 46700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2340, step 46800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2345, step 46900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2350, step 47000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2355, step 47100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2360, step 47200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2365, step 47300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2370, step 47400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2375, step 47500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2380, step 47600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2385, step 47700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2390, step 47800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2395, step 47900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2400, step 48000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2405, step 48100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2410, step 48200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2415, step 48300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2420, step 48400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2425, step 48500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2430, step 48600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2435, step 48700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2440, step 48800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2445, step 48900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2450, step 49000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2455, step 49100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2460, step 49200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2465, step 49300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2470, step 49400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2475, step 49500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2480, step 49600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2485, step 49700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2490, step 49800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2495, step 49900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2500, step 50000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2505, step 50100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2510, step 50200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2515, step 50300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2520, step 50400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2525, step 50500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2530, step 50600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2535, step 50700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2540, step 50800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2545, step 50900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2550, step 51000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2555, step 51100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2560, step 51200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2565, step 51300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2570, step 51400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2575, step 51500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2580, step 51600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2585, step 51700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2590, step 51800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2595, step 51900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2600, step 52000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2605, step 52100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2610, step 52200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2615, step 52300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2620, step 52400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2625, step 52500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2630, step 52600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2635, step 52700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2640, step 52800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2645, step 52900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2650, step 53000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2655, step 53100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2660, step 53200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2665, step 53300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2670, step 53400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2675, step 53500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2680, step 53600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2685, step 53700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2690, step 53800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2695, step 53900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2700, step 54000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2705, step 54100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2710, step 54200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2715, step 54300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2720, step 54400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2725, step 54500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2730, step 54600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2735, step 54700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2740, step 54800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2745, step 54900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2750, step 55000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2755, step 55100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2760, step 55200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2765, step 55300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2770, step 55400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2775, step 55500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2780, step 55600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2785, step 55700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2790, step 55800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2795, step 55900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2800, step 56000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2805, step 56100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2810, step 56200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2815, step 56300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2820, step 56400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2825, step 56500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2830, step 56600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2835, step 56700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2840, step 56800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2845, step 56900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2850, step 57000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2855, step 57100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2860, step 57200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2865, step 57300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2870, step 57400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2875, step 57500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2880, step 57600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2885, step 57700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2890, step 57800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2895, step 57900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2900, step 58000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2905, step 58100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2910, step 58200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2915, step 58300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2920, step 58400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2925, step 58500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2930, step 58600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2935, step 58700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2940, step 58800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2945, step 58900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2950, step 59000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2955, step 59100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2960, step 59200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2965, step 59300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2970, step 59400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2975, step 59500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2980, step 59600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2985, step 59700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2990, step 59800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2995, step 59900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3000, step 60000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3005, step 60100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3010, step 60200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3015, step 60300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3020, step 60400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3025, step 60500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3030, step 60600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3035, step 60700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3040, step 60800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3045, step 60900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3050, step 61000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3055, step 61100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3060, step 61200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3065, step 61300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3070, step 61400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3075, step 61500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3080, step 61600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3085, step 61700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3090, step 61800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3095, step 61900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3100, step 62000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3105, step 62100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3110, step 62200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3115, step 62300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3120, step 62400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3125, step 62500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3130, step 62600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3135, step 62700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3140, step 62800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3145, step 62900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3150, step 63000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3155, step 63100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3160, step 63200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3165, step 63300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3170, step 63400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3175, step 63500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3180, step 63600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3185, step 63700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3190, step 63800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3195, step 63900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3200, step 64000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3205, step 64100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3210, step 64200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3215, step 64300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3220, step 64400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3225, step 64500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3230, step 64600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3235, step 64700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3240, step 64800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3245, step 64900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3250, step 65000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3255, step 65100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3260, step 65200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3265, step 65300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3270, step 65400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3275, step 65500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3280, step 65600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3285, step 65700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3290, step 65800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3295, step 65900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3300, step 66000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3305, step 66100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3310, step 66200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3315, step 66300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3320, step 66400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3325, step 66500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3330, step 66600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3335, step 66700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3340, step 66800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3345, step 66900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3350, step 67000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3355, step 67100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3360, step 67200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3365, step 67300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3370, step 67400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3375, step 67500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3380, step 67600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3385, step 67700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3390, step 67800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3395, step 67900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3400, step 68000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3405, step 68100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3410, step 68200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3415, step 68300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3420, step 68400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3425, step 68500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3430, step 68600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3435, step 68700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3440, step 68800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3445, step 68900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3450, step 69000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3455, step 69100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3460, step 69200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3465, step 69300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3470, step 69400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3475, step 69500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3480, step 69600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3485, step 69700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3490, step 69800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3495, step 69900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3500, step 70000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3505, step 70100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3510, step 70200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3515, step 70300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3520, step 70400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3525, step 70500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3530, step 70600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3535, step 70700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3540, step 70800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3545, step 70900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3550, step 71000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3555, step 71100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3560, step 71200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3565, step 71300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3570, step 71400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3575, step 71500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3580, step 71600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3585, step 71700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3590, step 71800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3595, step 71900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3600, step 72000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3605, step 72100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3610, step 72200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3615, step 72300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3620, step 72400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3625, step 72500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3630, step 72600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3635, step 72700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3640, step 72800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3645, step 72900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3650, step 73000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3655, step 73100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3660, step 73200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3665, step 73300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3670, step 73400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3675, step 73500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3680, step 73600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3685, step 73700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3690, step 73800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3695, step 73900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3700, step 74000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3705, step 74100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3710, step 74200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3715, step 74300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3720, step 74400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3725, step 74500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3730, step 74600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3735, step 74700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3740, step 74800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3745, step 74900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3750, step 75000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3755, step 75100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3760, step 75200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3765, step 75300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3770, step 75400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3775, step 75500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3780, step 75600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3785, step 75700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3790, step 75800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3795, step 75900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3800, step 76000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3805, step 76100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3810, step 76200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3815, step 76300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3820, step 76400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3825, step 76500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3830, step 76600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3835, step 76700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3840, step 76800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3845, step 76900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3850, step 77000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3855, step 77100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3860, step 77200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3865, step 77300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3870, step 77400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3875, step 77500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3880, step 77600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3885, step 77700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3890, step 77800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3895, step 77900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3900, step 78000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3905, step 78100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3910, step 78200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3915, step 78300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3920, step 78400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3925, step 78500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3930, step 78600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3935, step 78700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3940, step 78800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3945, step 78900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3950, step 79000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3955, step 79100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3960, step 79200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3965, step 79300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3970, step 79400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3975, step 79500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3980, step 79600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3985, step 79700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 3990, step 79800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3995, step 79900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4000, step 80000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4005, step 80100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4010, step 80200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4015, step 80300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4020, step 80400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4025, step 80500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4030, step 80600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4035, step 80700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4040, step 80800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4045, step 80900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4050, step 81000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4055, step 81100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4060, step 81200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4065, step 81300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4070, step 81400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4075, step 81500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4080, step 81600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4085, step 81700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4090, step 81800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4095, step 81900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4100, step 82000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4105, step 82100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4110, step 82200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4115, step 82300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4120, step 82400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4125, step 82500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4130, step 82600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4135, step 82700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4140, step 82800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4145, step 82900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4150, step 83000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4155, step 83100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4160, step 83200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4165, step 83300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4170, step 83400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4175, step 83500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4180, step 83600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 4185, step 83700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4190, step 83800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4195, step 83900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4200, step 84000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4205, step 84100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4210, step 84200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4215, step 84300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4220, step 84400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4225, step 84500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4230, step 84600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4235, step 84700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4240, step 84800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4245, step 84900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4250, step 85000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4255, step 85100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4260, step 85200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4265, step 85300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4270, step 85400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4275, step 85500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4280, step 85600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4285, step 85700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4290, step 85800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4295, step 85900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4300, step 86000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4305, step 86100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4310, step 86200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4315, step 86300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4320, step 86400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4325, step 86500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4330, step 86600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4335, step 86700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4340, step 86800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4345, step 86900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4350, step 87000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4355, step 87100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4360, step 87200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4365, step 87300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4370, step 87400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4375, step 87500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4380, step 87600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4385, step 87700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4390, step 87800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4395, step 87900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4400, step 88000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4405, step 88100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4410, step 88200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4415, step 88300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4420, step 88400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4425, step 88500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4430, step 88600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4435, step 88700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4440, step 88800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4445, step 88900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4450, step 89000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4455, step 89100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4460, step 89200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4465, step 89300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4470, step 89400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4475, step 89500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4480, step 89600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4485, step 89700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4490, step 89800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4495, step 89900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4500, step 90000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4505, step 90100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4510, step 90200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4515, step 90300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4520, step 90400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4525, step 90500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4530, step 90600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4535, step 90700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4540, step 90800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4545, step 90900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4550, step 91000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4555, step 91100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4560, step 91200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4565, step 91300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4570, step 91400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4575, step 91500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4580, step 91600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4585, step 91700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4590, step 91800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4595, step 91900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4600, step 92000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4605, step 92100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4610, step 92200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4615, step 92300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4620, step 92400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4625, step 92500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4630, step 92600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4635, step 92700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4640, step 92800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4645, step 92900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4650, step 93000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4655, step 93100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4660, step 93200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4665, step 93300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4670, step 93400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4675, step 93500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4680, step 93600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4685, step 93700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4690, step 93800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4695, step 93900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4700, step 94000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4705, step 94100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4710, step 94200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4715, step 94300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4720, step 94400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4725, step 94500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4730, step 94600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4735, step 94700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4740, step 94800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4745, step 94900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4750, step 95000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4755, step 95100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4760, step 95200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4765, step 95300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4770, step 95400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4775, step 95500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4780, step 95600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4785, step 95700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4790, step 95800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4795, step 95900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4800, step 96000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4805, step 96100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4810, step 96200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4815, step 96300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4820, step 96400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4825, step 96500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4830, step 96600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4835, step 96700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4840, step 96800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4845, step 96900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4850, step 97000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4855, step 97100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4860, step 97200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4865, step 97300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4870, step 97400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4875, step 97500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4880, step 97600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4885, step 97700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4890, step 97800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4895, step 97900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4900, step 98000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4905, step 98100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4910, step 98200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4915, step 98300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4920, step 98400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4925, step 98500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4930, step 98600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4935, step 98700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4940, step 98800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4945, step 98900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4950, step 99000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4955, step 99100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4960, step 99200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4965, step 99300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4970, step 99400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4975, step 99500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4980, step 99600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4985, step 99700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4990, step 99800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4995, step 99900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 5000, step 100000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a pearl agent\n",
    "\n",
    "action_representation_module = IdentityActionRepresentationModule(\n",
    "    max_number_actions=action_space.n,\n",
    "    representation_dim=action_space.action_dim,\n",
    ")\n",
    "\n",
    "# DQN-vanilla\n",
    "agent = PearlAgent(\n",
    "    policy_learner=DeepQLearning(\n",
    "        state_dim=1,\n",
    "        action_space=action_space,\n",
    "        hidden_dims=[64, 64],\n",
    "        training_rounds=50,\n",
    "        action_representation_module=action_representation_module,\n",
    "    ),\n",
    "    replay_buffer=FIFOOffPolicyReplayBuffer(100_000),\n",
    "    device_id=-1,\n",
    ")\n",
    "\n",
    "info = online_learning(\n",
    "    agent=agent,\n",
    "    env=env,\n",
    "    number_of_steps=number_of_steps,\n",
    "    print_every_x_steps=100,\n",
    "    record_period=record_period,\n",
    "    learn_after_episode=True,\n",
    ")\n",
    "torch.save(info[\"return\"], \"DQN-return.pt\")\n",
    "plt.plot(record_period * np.arange(len(info[\"return\"])), info[\"return\"], label=\"DQN\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Agent with LSTM history summarization module\n",
    "\n",
    "Now the DQN agent can handle partially observable environments with history summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cDauzO74nS4c",
    "ExecuteTime": {
     "end_time": "2024-01-18T03:07:58.874641500Z",
     "start_time": "2024-01-18T02:23:02.381425600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5, step 100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 10, step 200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 15, step 300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 20, step 400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 25, step 500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 30, step 600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 35, step 700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 40, step 800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 45, step 900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 50, step 1000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 55, step 1100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 60, step 1200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 65, step 1300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 70, step 1400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 75, step 1500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 80, step 1600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 85, step 1700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 90, step 1800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 6.0\n",
      "episode 95, step 1900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 100, step 2000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 105, step 2100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 110, step 2200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 115, step 2300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 120, step 2400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 125, step 2500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 130, step 2600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 135, step 2700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 140, step 2800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 145, step 2900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 150, step 3000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 155, step 3100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 160, step 3200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 165, step 3300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 170, step 3400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 175, step 3500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 180, step 3600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 185, step 3700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 190, step 3800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 195, step 3900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 200, step 4000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 205, step 4100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 210, step 4200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 215, step 4300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 220, step 4400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 225, step 4500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 230, step 4600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 235, step 4700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 240, step 4800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 245, step 4900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 250, step 5000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 255, step 5100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 260, step 5200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 265, step 5300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 270, step 5400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 275, step 5500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 280, step 5600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 285, step 5700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 290, step 5800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 295, step 5900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 300, step 6000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 305, step 6100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 310, step 6200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 315, step 6300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 320, step 6400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 325, step 6500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 330, step 6600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 335, step 6700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 340, step 6800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 345, step 6900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 350, step 7000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 355, step 7100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 360, step 7200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 365, step 7300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 370, step 7400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 375, step 7500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 380, step 7600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 385, step 7700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 390, step 7800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 395, step 7900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 400, step 8000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 405, step 8100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 410, step 8200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 415, step 8300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 420, step 8400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 425, step 8500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 430, step 8600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 435, step 8700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 440, step 8800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 445, step 8900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 450, step 9000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 455, step 9100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 460, step 9200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 465, step 9300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 470, step 9400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 475, step 9500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 480, step 9600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 485, step 9700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 490, step 9800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 495, step 9900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 500, step 10000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 505, step 10100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 510, step 10200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 515, step 10300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 520, step 10400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 525, step 10500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 530, step 10600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 535, step 10700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 540, step 10800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 545, step 10900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 550, step 11000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 555, step 11100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 560, step 11200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 565, step 11300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 570, step 11400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 575, step 11500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 580, step 11600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 585, step 11700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 590, step 11800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 595, step 11900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 600, step 12000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 605, step 12100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 610, step 12200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 615, step 12300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 620, step 12400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 625, step 12500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 630, step 12600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 635, step 12700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 640, step 12800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 645, step 12900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 650, step 13000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 655, step 13100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 660, step 13200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 665, step 13300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 670, step 13400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 675, step 13500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 680, step 13600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 685, step 13700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 690, step 13800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 695, step 13900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 700, step 14000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 705, step 14100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 710, step 14200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 715, step 14300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 720, step 14400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 725, step 14500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 730, step 14600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 735, step 14700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 740, step 14800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 745, step 14900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 750, step 15000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 755, step 15100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 760, step 15200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 765, step 15300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 770, step 15400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 775, step 15500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 780, step 15600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 785, step 15700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 790, step 15800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 795, step 15900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 800, step 16000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 805, step 16100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 810, step 16200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 815, step 16300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 820, step 16400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 825, step 16500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 830, step 16600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 835, step 16700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 840, step 16800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 845, step 16900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 850, step 17000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 855, step 17100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 860, step 17200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 865, step 17300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 870, step 17400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 875, step 17500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 880, step 17600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 885, step 17700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 890, step 17800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 895, step 17900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 900, step 18000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 905, step 18100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 910, step 18200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 915, step 18300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 920, step 18400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 925, step 18500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 930, step 18600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 935, step 18700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 940, step 18800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 945, step 18900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 950, step 19000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 955, step 19100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 960, step 19200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 965, step 19300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 970, step 19400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 975, step 19500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 980, step 19600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 985, step 19700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 990, step 19800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 995, step 19900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1000, step 20000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1005, step 20100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1010, step 20200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1015, step 20300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1020, step 20400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1025, step 20500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1030, step 20600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1035, step 20700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1040, step 20800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1045, step 20900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1050, step 21000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1055, step 21100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1060, step 21200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1065, step 21300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1070, step 21400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1075, step 21500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1080, step 21600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1085, step 21700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1090, step 21800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1095, step 21900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1100, step 22000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1105, step 22100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1110, step 22200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1115, step 22300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1120, step 22400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1125, step 22500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1130, step 22600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1135, step 22700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1140, step 22800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1145, step 22900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1150, step 23000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1155, step 23100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1160, step 23200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1165, step 23300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1170, step 23400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1175, step 23500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1180, step 23600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1185, step 23700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1190, step 23800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1195, step 23900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1200, step 24000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1205, step 24100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1210, step 24200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 1215, step 24300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1220, step 24400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1225, step 24500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1230, step 24600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1235, step 24700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1240, step 24800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1245, step 24900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1250, step 25000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1255, step 25100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1260, step 25200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1265, step 25300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 1270, step 25400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1275, step 25500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1280, step 25600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1285, step 25700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1290, step 25800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1295, step 25900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1300, step 26000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1305, step 26100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1310, step 26200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1315, step 26300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1320, step 26400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1325, step 26500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1330, step 26600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1335, step 26700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1340, step 26800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1345, step 26900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1350, step 27000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1355, step 27100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1360, step 27200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1365, step 27300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1370, step 27400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1375, step 27500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1380, step 27600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1385, step 27700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1390, step 27800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1395, step 27900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1400, step 28000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1405, step 28100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1410, step 28200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1415, step 28300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1420, step 28400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1425, step 28500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1430, step 28600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1435, step 28700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1440, step 28800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1445, step 28900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1450, step 29000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1455, step 29100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1460, step 29200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1465, step 29300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1470, step 29400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1475, step 29500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1480, step 29600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1485, step 29700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1490, step 29800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1495, step 29900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1500, step 30000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1505, step 30100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1510, step 30200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1515, step 30300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1520, step 30400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1525, step 30500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1530, step 30600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1535, step 30700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1540, step 30800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1545, step 30900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1550, step 31000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1555, step 31100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1560, step 31200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1565, step 31300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1570, step 31400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1575, step 31500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1580, step 31600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1585, step 31700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1590, step 31800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1595, step 31900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1600, step 32000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1605, step 32100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1610, step 32200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1615, step 32300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1620, step 32400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1625, step 32500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1630, step 32600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1635, step 32700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1640, step 32800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1645, step 32900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1650, step 33000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1655, step 33100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1660, step 33200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1665, step 33300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1670, step 33400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1675, step 33500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1680, step 33600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1685, step 33700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1690, step 33800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1695, step 33900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1700, step 34000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1705, step 34100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1710, step 34200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 1715, step 34300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1720, step 34400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1725, step 34500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1730, step 34600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1735, step 34700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1740, step 34800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 1745, step 34900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1750, step 35000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1755, step 35100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1760, step 35200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1765, step 35300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1770, step 35400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1775, step 35500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1780, step 35600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1785, step 35700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1790, step 35800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1795, step 35900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1800, step 36000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1805, step 36100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1810, step 36200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1815, step 36300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1820, step 36400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1825, step 36500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1830, step 36600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1835, step 36700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 1840, step 36800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1845, step 36900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1850, step 37000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 1855, step 37100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1860, step 37200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1865, step 37300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1870, step 37400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1875, step 37500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1880, step 37600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1885, step 37700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1890, step 37800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1895, step 37900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1900, step 38000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1905, step 38100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1910, step 38200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1915, step 38300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1920, step 38400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1925, step 38500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1930, step 38600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1935, step 38700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1940, step 38800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1945, step 38900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 1950, step 39000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1955, step 39100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 1960, step 39200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1965, step 39300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1970, step 39400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 1975, step 39500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 1980, step 39600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1985, step 39700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 1990, step 39800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 1995, step 39900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2000, step 40000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2005, step 40100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2010, step 40200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2015, step 40300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2020, step 40400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2025, step 40500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2030, step 40600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2035, step 40700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 6.0\n",
      "episode 2040, step 40800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2045, step 40900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 6.0\n",
      "episode 2050, step 41000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2055, step 41100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2060, step 41200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 2065, step 41300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2070, step 41400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2075, step 41500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 2080, step 41600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2085, step 41700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2090, step 41800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2095, step 41900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2100, step 42000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2105, step 42100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2110, step 42200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2115, step 42300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2120, step 42400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2125, step 42500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2130, step 42600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2135, step 42700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2140, step 42800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2145, step 42900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2150, step 43000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2155, step 43100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2160, step 43200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2165, step 43300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2170, step 43400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2175, step 43500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2180, step 43600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2185, step 43700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2190, step 43800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 2195, step 43900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2200, step 44000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2205, step 44100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2210, step 44200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2215, step 44300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2220, step 44400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2225, step 44500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2230, step 44600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 2235, step 44700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2240, step 44800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2245, step 44900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2250, step 45000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2255, step 45100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2260, step 45200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2265, step 45300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2270, step 45400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2275, step 45500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2280, step 45600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2285, step 45700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2290, step 45800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2295, step 45900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2300, step 46000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2305, step 46100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2310, step 46200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2315, step 46300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2320, step 46400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2325, step 46500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2330, step 46600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2335, step 46700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2340, step 46800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2345, step 46900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2350, step 47000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2355, step 47100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2360, step 47200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2365, step 47300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2370, step 47400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2375, step 47500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2380, step 47600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2385, step 47700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 2390, step 47800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2395, step 47900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2400, step 48000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2405, step 48100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2410, step 48200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2415, step 48300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2420, step 48400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2425, step 48500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2430, step 48600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2435, step 48700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2440, step 48800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2445, step 48900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2450, step 49000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2455, step 49100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2460, step 49200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2465, step 49300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2470, step 49400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2475, step 49500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2480, step 49600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2485, step 49700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 6.0\n",
      "episode 2490, step 49800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2495, step 49900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2500, step 50000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2505, step 50100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2510, step 50200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2515, step 50300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2520, step 50400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2525, step 50500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2530, step 50600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2535, step 50700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2540, step 50800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2545, step 50900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2550, step 51000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2555, step 51100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2560, step 51200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2565, step 51300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2570, step 51400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2575, step 51500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2580, step 51600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2585, step 51700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2590, step 51800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2595, step 51900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2600, step 52000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2605, step 52100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2610, step 52200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2615, step 52300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2620, step 52400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2625, step 52500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2630, step 52600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2635, step 52700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2640, step 52800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2645, step 52900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2650, step 53000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2655, step 53100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2660, step 53200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2665, step 53300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2670, step 53400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2675, step 53500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2680, step 53600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2685, step 53700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2690, step 53800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2695, step 53900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2700, step 54000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2705, step 54100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2710, step 54200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2715, step 54300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2720, step 54400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2725, step 54500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2730, step 54600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2735, step 54700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2740, step 54800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2745, step 54900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2750, step 55000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2755, step 55100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2760, step 55200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2765, step 55300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2770, step 55400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2775, step 55500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2780, step 55600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2785, step 55700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2790, step 55800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2795, step 55900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2800, step 56000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2805, step 56100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2810, step 56200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2815, step 56300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2820, step 56400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2825, step 56500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2830, step 56600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2835, step 56700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2840, step 56800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2845, step 56900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2850, step 57000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2855, step 57100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2860, step 57200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2865, step 57300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2870, step 57400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2875, step 57500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2880, step 57600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2885, step 57700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2890, step 57800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2895, step 57900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2900, step 58000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2905, step 58100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2910, step 58200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2915, step 58300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2920, step 58400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2925, step 58500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2930, step 58600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 2935, step 58700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2940, step 58800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2945, step 58900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2950, step 59000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2955, step 59100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 2960, step 59200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2965, step 59300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2970, step 59400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2975, step 59500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2980, step 59600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 2985, step 59700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 2990, step 59800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 2995, step 59900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3000, step 60000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3005, step 60100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3010, step 60200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3015, step 60300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3020, step 60400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3025, step 60500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3030, step 60600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3035, step 60700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3040, step 60800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3045, step 60900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3050, step 61000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3055, step 61100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3060, step 61200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3065, step 61300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3070, step 61400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3075, step 61500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3080, step 61600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3085, step 61700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3090, step 61800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3095, step 61900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3100, step 62000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3105, step 62100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3110, step 62200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3115, step 62300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3120, step 62400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3125, step 62500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3130, step 62600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3135, step 62700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3140, step 62800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3145, step 62900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3150, step 63000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3155, step 63100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3160, step 63200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3165, step 63300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3170, step 63400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3175, step 63500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3180, step 63600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3185, step 63700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3190, step 63800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3195, step 63900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3200, step 64000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3205, step 64100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3210, step 64200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3215, step 64300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3220, step 64400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3225, step 64500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3230, step 64600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3235, step 64700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3240, step 64800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3245, step 64900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3250, step 65000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3255, step 65100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3260, step 65200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3265, step 65300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3270, step 65400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3275, step 65500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3280, step 65600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3285, step 65700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3290, step 65800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3295, step 65900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3300, step 66000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3305, step 66100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3310, step 66200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3315, step 66300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3320, step 66400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3325, step 66500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3330, step 66600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3335, step 66700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3340, step 66800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3345, step 66900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3350, step 67000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3355, step 67100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3360, step 67200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3365, step 67300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3370, step 67400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3375, step 67500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3380, step 67600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3385, step 67700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3390, step 67800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3395, step 67900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3400, step 68000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3405, step 68100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3410, step 68200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3415, step 68300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3420, step 68400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3425, step 68500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3430, step 68600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3435, step 68700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3440, step 68800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3445, step 68900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3450, step 69000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3455, step 69100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3460, step 69200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3465, step 69300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3470, step 69400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3475, step 69500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3480, step 69600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3485, step 69700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3490, step 69800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3495, step 69900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3500, step 70000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 3505, step 70100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3510, step 70200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3515, step 70300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3520, step 70400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3525, step 70500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3530, step 70600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3535, step 70700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3540, step 70800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3545, step 70900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3550, step 71000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3555, step 71100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 3560, step 71200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3565, step 71300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3570, step 71400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3575, step 71500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3580, step 71600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 3585, step 71700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3590, step 71800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3595, step 71900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3600, step 72000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3605, step 72100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 3610, step 72200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3615, step 72300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3620, step 72400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3625, step 72500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3630, step 72600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3635, step 72700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3640, step 72800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3645, step 72900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3650, step 73000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3655, step 73100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3660, step 73200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3665, step 73300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3670, step 73400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3675, step 73500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3680, step 73600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3685, step 73700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3690, step 73800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3695, step 73900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3700, step 74000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3705, step 74100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3710, step 74200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3715, step 74300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3720, step 74400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3725, step 74500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3730, step 74600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3735, step 74700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3740, step 74800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3745, step 74900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3750, step 75000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3755, step 75100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3760, step 75200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3765, step 75300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3770, step 75400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 6.0\n",
      "episode 3775, step 75500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3780, step 75600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3785, step 75700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3790, step 75800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3795, step 75900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3800, step 76000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3805, step 76100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3810, step 76200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3815, step 76300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 3820, step 76400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3825, step 76500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3830, step 76600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3835, step 76700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3840, step 76800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3845, step 76900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3850, step 77000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3855, step 77100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3860, step 77200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3865, step 77300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3870, step 77400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3875, step 77500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3880, step 77600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3885, step 77700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3890, step 77800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3895, step 77900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3900, step 78000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3905, step 78100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3910, step 78200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3915, step 78300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3920, step 78400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3925, step 78500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3930, step 78600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3935, step 78700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 3940, step 78800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3945, step 78900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3950, step 79000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 3955, step 79100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3960, step 79200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3965, step 79300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 3970, step 79400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3975, step 79500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3980, step 79600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 3985, step 79700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 3990, step 79800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 3995, step 79900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4000, step 80000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4005, step 80100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4010, step 80200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4015, step 80300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4020, step 80400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4025, step 80500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4030, step 80600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4035, step 80700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4040, step 80800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4045, step 80900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4050, step 81000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4055, step 81100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4060, step 81200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4065, step 81300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4070, step 81400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4075, step 81500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4080, step 81600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4085, step 81700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4090, step 81800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4095, step 81900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4100, step 82000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4105, step 82100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4110, step 82200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4115, step 82300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4120, step 82400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4125, step 82500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4130, step 82600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4135, step 82700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4140, step 82800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4145, step 82900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4150, step 83000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4155, step 83100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4160, step 83200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4165, step 83300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4170, step 83400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4175, step 83500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4180, step 83600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4185, step 83700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4190, step 83800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4195, step 83900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4200, step 84000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4205, step 84100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4210, step 84200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4215, step 84300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4220, step 84400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4225, step 84500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4230, step 84600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4235, step 84700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4240, step 84800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4245, step 84900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4250, step 85000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4255, step 85100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4260, step 85200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4265, step 85300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4270, step 85400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4275, step 85500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4280, step 85600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4285, step 85700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4290, step 85800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4295, step 85900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4300, step 86000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4305, step 86100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 4310, step 86200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4315, step 86300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 4320, step 86400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4325, step 86500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4330, step 86600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4335, step 86700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4340, step 86800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4345, step 86900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4350, step 87000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4355, step 87100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4360, step 87200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4365, step 87300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4370, step 87400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4375, step 87500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4380, step 87600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4385, step 87700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4390, step 87800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4395, step 87900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4400, step 88000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4405, step 88100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4410, step 88200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4415, step 88300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4420, step 88400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4425, step 88500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4430, step 88600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4435, step 88700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4440, step 88800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4445, step 88900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4450, step 89000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4455, step 89100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4460, step 89200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4465, step 89300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4470, step 89400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4475, step 89500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4480, step 89600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4485, step 89700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4490, step 89800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4495, step 89900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4500, step 90000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4505, step 90100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4510, step 90200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4515, step 90300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4520, step 90400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4525, step 90500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4530, step 90600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4535, step 90700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4540, step 90800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4545, step 90900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4550, step 91000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4555, step 91100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 7.0\n",
      "episode 4560, step 91200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4565, step 91300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 4570, step 91400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4575, step 91500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4580, step 91600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 4585, step 91700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4590, step 91800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4595, step 91900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4600, step 92000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4605, step 92100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4610, step 92200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4615, step 92300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4620, step 92400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4625, step 92500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4630, step 92600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4635, step 92700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4640, step 92800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4645, step 92900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4650, step 93000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4655, step 93100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4660, step 93200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4665, step 93300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4670, step 93400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4675, step 93500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4680, step 93600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4685, step 93700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4690, step 93800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4695, step 93900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4700, step 94000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4705, step 94100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4710, step 94200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4715, step 94300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4720, step 94400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4725, step 94500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4730, step 94600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4735, step 94700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4740, step 94800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4745, step 94900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4750, step 95000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4755, step 95100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4760, step 95200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4765, step 95300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4770, step 95400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4775, step 95500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4780, step 95600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4785, step 95700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4790, step 95800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4795, step 95900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4800, step 96000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4805, step 96100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 4810, step 96200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4815, step 96300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4820, step 96400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4825, step 96500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4830, step 96600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4835, step 96700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4840, step 96800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4845, step 96900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4850, step 97000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4855, step 97100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4860, step 97200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4865, step 97300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4870, step 97400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4875, step 97500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4880, step 97600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4885, step 97700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4890, step 97800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4895, step 97900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4900, step 98000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 4905, step 98100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 4910, step 98200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4915, step 98300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4920, step 98400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 0.0\n",
      "episode 4925, step 98500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4930, step 98600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4935, step 98700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4940, step 98800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 5.0\n",
      "episode 4945, step 98900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4950, step 99000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4955, step 99100, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4960, step 99200, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4965, step 99300, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4970, step 99400, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4975, step 99500, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n",
      "episode 4980, step 99600, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4985, step 99700, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 3.0\n",
      "episode 4990, step 99800, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 1.0\n",
      "episode 4995, step 99900, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 4.0\n",
      "episode 5000, step 100000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000001E2E17DC640>\n",
      "return: 2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add a LSTM history summarization module\n",
    "\n",
    "agent = PearlAgent(\n",
    "    policy_learner=DeepQLearning(\n",
    "        state_dim=128,\n",
    "        action_space=action_space,\n",
    "        hidden_dims=[64, 64],\n",
    "        training_rounds=50,\n",
    "        action_representation_module=action_representation_module,\n",
    "    ),\n",
    "    history_summarization_module=LSTMHistorySummarizationModule(\n",
    "        observation_dim=1,\n",
    "        action_dim=100,\n",
    "        hidden_dim=128,\n",
    "        history_length=8,\n",
    "    ),\n",
    "    replay_buffer=FIFOOffPolicyReplayBuffer(100_000),\n",
    "    device_id=-1,\n",
    ")\n",
    "\n",
    "info = online_learning(\n",
    "    agent=agent,\n",
    "    env=env,\n",
    "    number_of_steps=number_of_steps,\n",
    "    print_every_x_steps=100,\n",
    "    record_period=record_period,\n",
    "    learn_after_episode=True,\n",
    ")\n",
    "torch.save(info[\"return\"], \"DQN-LSTM-return.pt\")\n",
    "plt.plot(record_period * np.arange(len(info[\"return\"])), info[\"return\"], label=\"DQN-LSTM\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapped DQN Agent with LSTM History Summarization\n",
    "\n",
    "Leveraging the deep exploration value-based algorithm, now the agent can achieve a better performance in a much faster way while being able to still leverage history summarization capability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_7Cpzoi3nVAw",
    "ExecuteTime": {
     "end_time": "2024-01-18T20:25:01.705435900Z",
     "start_time": "2024-01-18T18:19:54.272645200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5, step 100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 10, step 200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 15, step 300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 20, step 400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 25, step 500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 30, step 600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 35, step 700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 40, step 800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 45, step 900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 50, step 1000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 55, step 1100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 60, step 1200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 65, step 1300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 70, step 1400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 75, step 1500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 80, step 1600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 85, step 1700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 90, step 1800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 95, step 1900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 100, step 2000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 105, step 2100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 110, step 2200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 115, step 2300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 120, step 2400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 125, step 2500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 130, step 2600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 135, step 2700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 140, step 2800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 145, step 2900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 150, step 3000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 155, step 3100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 160, step 3200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 165, step 3300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 170, step 3400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 175, step 3500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 180, step 3600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 185, step 3700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 190, step 3800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 195, step 3900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 200, step 4000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 205, step 4100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 210, step 4200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 215, step 4300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 7.0\n",
      "episode 220, step 4400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 225, step 4500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 230, step 4600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 235, step 4700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 240, step 4800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 245, step 4900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 250, step 5000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 255, step 5100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 260, step 5200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 265, step 5300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 270, step 5400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 275, step 5500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 280, step 5600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 285, step 5700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 290, step 5800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 295, step 5900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 300, step 6000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 305, step 6100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 310, step 6200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 315, step 6300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 320, step 6400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 325, step 6500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 330, step 6600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 335, step 6700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 340, step 6800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 345, step 6900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 350, step 7000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 355, step 7100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 360, step 7200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 365, step 7300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 370, step 7400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 375, step 7500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 380, step 7600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 385, step 7700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 390, step 7800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 395, step 7900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 400, step 8000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 405, step 8100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 410, step 8200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 415, step 8300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 420, step 8400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 425, step 8500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 430, step 8600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 435, step 8700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 440, step 8800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 445, step 8900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 450, step 9000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 455, step 9100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 460, step 9200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 465, step 9300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 470, step 9400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 475, step 9500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 480, step 9600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 485, step 9700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 490, step 9800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 495, step 9900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 500, step 10000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 505, step 10100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 510, step 10200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 515, step 10300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 520, step 10400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 525, step 10500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 530, step 10600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 535, step 10700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 540, step 10800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 545, step 10900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 550, step 11000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 555, step 11100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 560, step 11200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 565, step 11300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 570, step 11400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 575, step 11500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 580, step 11600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 585, step 11700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 590, step 11800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 595, step 11900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 600, step 12000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 605, step 12100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 610, step 12200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 615, step 12300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 620, step 12400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 625, step 12500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 630, step 12600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 635, step 12700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 640, step 12800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 645, step 12900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 650, step 13000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 655, step 13100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 660, step 13200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 665, step 13300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 670, step 13400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 675, step 13500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 680, step 13600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 685, step 13700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 690, step 13800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 695, step 13900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 700, step 14000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 705, step 14100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 710, step 14200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 715, step 14300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 720, step 14400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 725, step 14500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 730, step 14600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 735, step 14700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 740, step 14800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 745, step 14900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 750, step 15000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 755, step 15100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 760, step 15200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 765, step 15300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 770, step 15400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 775, step 15500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 780, step 15600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 785, step 15700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 790, step 15800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 795, step 15900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 800, step 16000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 805, step 16100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 810, step 16200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 815, step 16300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 820, step 16400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 825, step 16500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 830, step 16600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 835, step 16700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 840, step 16800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 845, step 16900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 850, step 17000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 855, step 17100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 860, step 17200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 865, step 17300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 870, step 17400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 875, step 17500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 880, step 17600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 885, step 17700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 890, step 17800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 895, step 17900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 900, step 18000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 905, step 18100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 910, step 18200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 915, step 18300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 920, step 18400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 925, step 18500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 930, step 18600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 935, step 18700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 940, step 18800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 945, step 18900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 950, step 19000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 955, step 19100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 960, step 19200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 965, step 19300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 970, step 19400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 975, step 19500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 980, step 19600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 985, step 19700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 990, step 19800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 995, step 19900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1000, step 20000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1005, step 20100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1010, step 20200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1015, step 20300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1020, step 20400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1025, step 20500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1030, step 20600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1035, step 20700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1040, step 20800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1045, step 20900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1050, step 21000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1055, step 21100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1060, step 21200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1065, step 21300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1070, step 21400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1075, step 21500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1080, step 21600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1085, step 21700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1090, step 21800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1095, step 21900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1100, step 22000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1105, step 22100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1110, step 22200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1115, step 22300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1120, step 22400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1125, step 22500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1130, step 22600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 1135, step 22700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1140, step 22800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1145, step 22900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1150, step 23000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1155, step 23100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1160, step 23200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1165, step 23300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1170, step 23400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1175, step 23500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1180, step 23600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1185, step 23700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1190, step 23800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 1195, step 23900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1200, step 24000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1205, step 24100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1210, step 24200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1215, step 24300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1220, step 24400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1225, step 24500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1230, step 24600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1235, step 24700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1240, step 24800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1245, step 24900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1250, step 25000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1255, step 25100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1260, step 25200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1265, step 25300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1270, step 25400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1275, step 25500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1280, step 25600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1285, step 25700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1290, step 25800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1295, step 25900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1300, step 26000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1305, step 26100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1310, step 26200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1315, step 26300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1320, step 26400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1325, step 26500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1330, step 26600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1335, step 26700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1340, step 26800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1345, step 26900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1350, step 27000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1355, step 27100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1360, step 27200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1365, step 27300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1370, step 27400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1375, step 27500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1380, step 27600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1385, step 27700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1390, step 27800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1395, step 27900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1400, step 28000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1405, step 28100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1410, step 28200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1415, step 28300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1420, step 28400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1425, step 28500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1430, step 28600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1435, step 28700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1440, step 28800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1445, step 28900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1450, step 29000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1455, step 29100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1460, step 29200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 1465, step 29300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1470, step 29400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1475, step 29500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1480, step 29600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1485, step 29700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1490, step 29800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1495, step 29900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1500, step 30000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1505, step 30100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1510, step 30200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1515, step 30300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 1520, step 30400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1525, step 30500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1530, step 30600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1535, step 30700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1540, step 30800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1545, step 30900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1550, step 31000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1555, step 31100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1560, step 31200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1565, step 31300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1570, step 31400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1575, step 31500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1580, step 31600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1585, step 31700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1590, step 31800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1595, step 31900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1600, step 32000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1605, step 32100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1610, step 32200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1615, step 32300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1620, step 32400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1625, step 32500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1630, step 32600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1635, step 32700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1640, step 32800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1645, step 32900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1650, step 33000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1655, step 33100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1660, step 33200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 1665, step 33300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1670, step 33400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1675, step 33500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1680, step 33600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1685, step 33700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1690, step 33800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1695, step 33900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1700, step 34000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1705, step 34100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1710, step 34200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1715, step 34300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1720, step 34400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1725, step 34500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1730, step 34600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1735, step 34700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1740, step 34800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1745, step 34900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1750, step 35000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1755, step 35100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1760, step 35200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1765, step 35300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1770, step 35400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1775, step 35500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1780, step 35600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1785, step 35700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1790, step 35800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1795, step 35900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1800, step 36000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1805, step 36100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1810, step 36200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1815, step 36300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1820, step 36400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1825, step 36500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1830, step 36600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1835, step 36700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1840, step 36800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1845, step 36900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1850, step 37000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1855, step 37100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1860, step 37200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1865, step 37300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1870, step 37400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1875, step 37500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1880, step 37600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1885, step 37700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1890, step 37800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1895, step 37900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1900, step 38000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1905, step 38100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1910, step 38200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1915, step 38300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1920, step 38400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1925, step 38500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1930, step 38600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1935, step 38700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1940, step 38800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1945, step 38900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1950, step 39000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1955, step 39100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1960, step 39200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1965, step 39300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1970, step 39400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1975, step 39500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1980, step 39600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1985, step 39700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1990, step 39800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1995, step 39900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2000, step 40000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2005, step 40100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2010, step 40200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2015, step 40300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2020, step 40400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 2025, step 40500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 2030, step 40600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2035, step 40700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2040, step 40800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2045, step 40900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2050, step 41000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2055, step 41100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2060, step 41200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2065, step 41300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2070, step 41400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2075, step 41500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2080, step 41600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2085, step 41700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2090, step 41800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2095, step 41900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2100, step 42000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2105, step 42100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2110, step 42200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2115, step 42300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2120, step 42400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2125, step 42500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2130, step 42600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2135, step 42700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2140, step 42800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2145, step 42900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2150, step 43000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2155, step 43100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2160, step 43200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2165, step 43300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2170, step 43400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2175, step 43500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2180, step 43600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 2185, step 43700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2190, step 43800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2195, step 43900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2200, step 44000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2205, step 44100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2210, step 44200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2215, step 44300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2220, step 44400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 2225, step 44500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2230, step 44600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2235, step 44700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2240, step 44800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2245, step 44900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2250, step 45000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2255, step 45100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2260, step 45200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2265, step 45300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2270, step 45400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2275, step 45500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2280, step 45600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2285, step 45700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2290, step 45800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2295, step 45900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2300, step 46000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2305, step 46100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2310, step 46200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2315, step 46300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2320, step 46400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2325, step 46500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2330, step 46600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2335, step 46700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2340, step 46800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2345, step 46900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2350, step 47000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2355, step 47100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2360, step 47200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2365, step 47300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2370, step 47400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2375, step 47500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2380, step 47600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2385, step 47700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2390, step 47800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2395, step 47900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2400, step 48000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2405, step 48100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2410, step 48200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2415, step 48300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 2420, step 48400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2425, step 48500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2430, step 48600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2435, step 48700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2440, step 48800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2445, step 48900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2450, step 49000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2455, step 49100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2460, step 49200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2465, step 49300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2470, step 49400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2475, step 49500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2480, step 49600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2485, step 49700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2490, step 49800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2495, step 49900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2500, step 50000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2505, step 50100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2510, step 50200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2515, step 50300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2520, step 50400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2525, step 50500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2530, step 50600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2535, step 50700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2540, step 50800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2545, step 50900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2550, step 51000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2555, step 51100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2560, step 51200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2565, step 51300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2570, step 51400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2575, step 51500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2580, step 51600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2585, step 51700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2590, step 51800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2595, step 51900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2600, step 52000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2605, step 52100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2610, step 52200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2615, step 52300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2620, step 52400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2625, step 52500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2630, step 52600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2635, step 52700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2640, step 52800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2645, step 52900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2650, step 53000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2655, step 53100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2660, step 53200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2665, step 53300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2670, step 53400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2675, step 53500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2680, step 53600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2685, step 53700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2690, step 53800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2695, step 53900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2700, step 54000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 2705, step 54100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2710, step 54200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2715, step 54300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2720, step 54400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2725, step 54500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2730, step 54600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2735, step 54700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2740, step 54800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2745, step 54900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2750, step 55000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2755, step 55100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2760, step 55200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2765, step 55300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2770, step 55400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2775, step 55500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2780, step 55600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2785, step 55700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2790, step 55800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2795, step 55900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2800, step 56000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2805, step 56100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2810, step 56200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2815, step 56300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2820, step 56400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2825, step 56500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2830, step 56600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2835, step 56700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2840, step 56800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2845, step 56900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2850, step 57000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2855, step 57100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2860, step 57200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2865, step 57300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2870, step 57400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2875, step 57500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2880, step 57600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2885, step 57700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2890, step 57800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2895, step 57900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2900, step 58000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2905, step 58100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2910, step 58200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2915, step 58300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2920, step 58400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2925, step 58500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2930, step 58600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2935, step 58700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2940, step 58800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2945, step 58900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2950, step 59000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2955, step 59100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2960, step 59200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2965, step 59300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2970, step 59400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2975, step 59500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2980, step 59600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2985, step 59700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2990, step 59800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2995, step 59900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3000, step 60000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3005, step 60100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3010, step 60200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3015, step 60300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3020, step 60400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3025, step 60500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3030, step 60600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3035, step 60700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3040, step 60800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3045, step 60900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3050, step 61000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3055, step 61100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3060, step 61200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3065, step 61300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3070, step 61400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3075, step 61500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3080, step 61600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3085, step 61700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3090, step 61800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3095, step 61900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3100, step 62000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3105, step 62100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3110, step 62200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3115, step 62300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3120, step 62400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3125, step 62500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3130, step 62600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3135, step 62700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3140, step 62800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 3145, step 62900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3150, step 63000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3155, step 63100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3160, step 63200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3165, step 63300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3170, step 63400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3175, step 63500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3180, step 63600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3185, step 63700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3190, step 63800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3195, step 63900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3200, step 64000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3205, step 64100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3210, step 64200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3215, step 64300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3220, step 64400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 3225, step 64500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3230, step 64600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3235, step 64700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3240, step 64800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3245, step 64900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3250, step 65000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3255, step 65100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3260, step 65200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3265, step 65300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3270, step 65400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3275, step 65500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3280, step 65600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3285, step 65700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3290, step 65800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3295, step 65900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3300, step 66000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3305, step 66100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3310, step 66200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3315, step 66300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3320, step 66400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3325, step 66500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3330, step 66600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3335, step 66700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3340, step 66800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3345, step 66900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3350, step 67000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3355, step 67100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3360, step 67200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3365, step 67300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3370, step 67400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3375, step 67500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3380, step 67600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3385, step 67700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3390, step 67800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3395, step 67900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3400, step 68000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3405, step 68100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3410, step 68200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3415, step 68300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3420, step 68400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3425, step 68500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3430, step 68600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3435, step 68700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3440, step 68800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3445, step 68900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3450, step 69000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3455, step 69100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3460, step 69200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3465, step 69300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3470, step 69400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3475, step 69500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3480, step 69600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3485, step 69700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3490, step 69800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3495, step 69900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3500, step 70000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3505, step 70100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3510, step 70200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3515, step 70300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3520, step 70400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3525, step 70500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3530, step 70600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3535, step 70700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3540, step 70800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3545, step 70900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3550, step 71000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3555, step 71100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3560, step 71200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3565, step 71300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3570, step 71400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3575, step 71500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3580, step 71600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3585, step 71700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3590, step 71800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3595, step 71900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3600, step 72000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3605, step 72100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3610, step 72200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3615, step 72300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3620, step 72400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3625, step 72500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3630, step 72600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3635, step 72700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3640, step 72800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3645, step 72900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3650, step 73000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3655, step 73100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3660, step 73200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3665, step 73300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3670, step 73400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3675, step 73500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3680, step 73600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3685, step 73700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3690, step 73800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3695, step 73900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3700, step 74000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3705, step 74100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3710, step 74200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3715, step 74300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3720, step 74400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3725, step 74500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3730, step 74600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3735, step 74700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3740, step 74800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3745, step 74900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3750, step 75000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3755, step 75100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3760, step 75200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3765, step 75300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3770, step 75400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3775, step 75500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3780, step 75600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3785, step 75700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3790, step 75800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3795, step 75900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3800, step 76000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3805, step 76100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3810, step 76200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3815, step 76300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3820, step 76400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3825, step 76500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3830, step 76600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3835, step 76700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3840, step 76800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3845, step 76900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3850, step 77000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3855, step 77100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3860, step 77200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3865, step 77300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3870, step 77400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3875, step 77500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3880, step 77600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3885, step 77700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3890, step 77800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3895, step 77900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3900, step 78000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3905, step 78100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3910, step 78200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3915, step 78300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 3920, step 78400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3925, step 78500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3930, step 78600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3935, step 78700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3940, step 78800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3945, step 78900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3950, step 79000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3955, step 79100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3960, step 79200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3965, step 79300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3970, step 79400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3975, step 79500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3980, step 79600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3985, step 79700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3990, step 79800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3995, step 79900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4000, step 80000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4005, step 80100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4010, step 80200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4015, step 80300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4020, step 80400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4025, step 80500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4030, step 80600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4035, step 80700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4040, step 80800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4045, step 80900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4050, step 81000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4055, step 81100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4060, step 81200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4065, step 81300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4070, step 81400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4075, step 81500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4080, step 81600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4085, step 81700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4090, step 81800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4095, step 81900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4100, step 82000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4105, step 82100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4110, step 82200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4115, step 82300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4120, step 82400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4125, step 82500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4130, step 82600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4135, step 82700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4140, step 82800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4145, step 82900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4150, step 83000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4155, step 83100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4160, step 83200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4165, step 83300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4170, step 83400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4175, step 83500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4180, step 83600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4185, step 83700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4190, step 83800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4195, step 83900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4200, step 84000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4205, step 84100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4210, step 84200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4215, step 84300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4220, step 84400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4225, step 84500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4230, step 84600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4235, step 84700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4240, step 84800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4245, step 84900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4250, step 85000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4255, step 85100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4260, step 85200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4265, step 85300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4270, step 85400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4275, step 85500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4280, step 85600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4285, step 85700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4290, step 85800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4295, step 85900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4300, step 86000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4305, step 86100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4310, step 86200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4315, step 86300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4320, step 86400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 4325, step 86500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4330, step 86600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4335, step 86700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4340, step 86800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4345, step 86900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4350, step 87000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4355, step 87100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4360, step 87200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4365, step 87300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4370, step 87400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4375, step 87500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4380, step 87600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4385, step 87700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4390, step 87800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4395, step 87900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4400, step 88000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4405, step 88100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4410, step 88200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4415, step 88300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4420, step 88400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4425, step 88500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4430, step 88600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4435, step 88700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4440, step 88800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4445, step 88900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4450, step 89000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4455, step 89100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4460, step 89200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4465, step 89300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4470, step 89400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4475, step 89500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4480, step 89600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4485, step 89700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4490, step 89800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4495, step 89900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4500, step 90000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4505, step 90100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4510, step 90200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4515, step 90300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4520, step 90400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4525, step 90500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4530, step 90600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4535, step 90700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4540, step 90800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4545, step 90900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4550, step 91000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4555, step 91100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4560, step 91200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4565, step 91300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4570, step 91400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4575, step 91500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4580, step 91600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4585, step 91700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4590, step 91800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4595, step 91900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4600, step 92000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4605, step 92100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4610, step 92200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4615, step 92300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4620, step 92400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4625, step 92500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4630, step 92600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4635, step 92700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4640, step 92800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4645, step 92900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4650, step 93000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4655, step 93100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4660, step 93200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4665, step 93300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4670, step 93400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4675, step 93500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4680, step 93600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4685, step 93700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4690, step 93800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4695, step 93900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4700, step 94000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4705, step 94100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4710, step 94200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4715, step 94300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4720, step 94400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4725, step 94500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4730, step 94600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4735, step 94700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4740, step 94800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4745, step 94900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4750, step 95000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4755, step 95100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4760, step 95200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4765, step 95300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4770, step 95400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4775, step 95500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4780, step 95600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4785, step 95700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4790, step 95800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4795, step 95900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4800, step 96000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4805, step 96100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4810, step 96200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4815, step 96300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4820, step 96400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4825, step 96500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4830, step 96600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4835, step 96700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4840, step 96800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4845, step 96900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4850, step 97000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4855, step 97100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4860, step 97200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4865, step 97300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4870, step 97400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4875, step 97500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4880, step 97600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4885, step 97700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4890, step 97800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4895, step 97900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4900, step 98000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4905, step 98100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4910, step 98200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4915, step 98300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4920, step 98400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4925, step 98500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4930, step 98600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4935, step 98700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4940, step 98800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4945, step 98900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4950, step 99000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4955, step 99100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4960, step 99200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4965, step 99300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4970, step 99400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4975, step 99500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4980, step 99600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4985, step 99700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4990, step 99800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4995, step 99900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 5000, step 100000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
      "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Better exploration with BootstrappedDQN-LSTM\n",
    "\n",
    "agent = PearlAgent(\n",
    "    policy_learner=BootstrappedDQN(\n",
    "        q_ensemble_network=EnsembleQValueNetwork(\n",
    "            state_dim=128,\n",
    "            action_dim=100,\n",
    "            ensemble_size=10,\n",
    "            output_dim=1,\n",
    "            hidden_dims=[64, 64],\n",
    "            prior_scale=0.3,\n",
    "        ),\n",
    "        action_space=action_space,\n",
    "        training_rounds=50,\n",
    "        action_representation_module=action_representation_module,\n",
    "    ),\n",
    "    history_summarization_module=LSTMHistorySummarizationModule(\n",
    "        observation_dim=1,\n",
    "        action_dim=100,\n",
    "        hidden_dim=128,\n",
    "        history_length=8,\n",
    "    ),\n",
    "    replay_buffer=BootstrapReplayBuffer(100_000, 1.0, 10),\n",
    "    device_id=-1,\n",
    ")\n",
    "\n",
    "info = online_learning(\n",
    "    agent=agent,\n",
    "    env=env,\n",
    "    number_of_steps=number_of_steps,\n",
    "    print_every_x_steps=100,\n",
    "    record_period=record_period,\n",
    "    learn_after_episode=True,\n",
    ")\n",
    "torch.save(info[\"return\"], \"BootstrappedDQN-LSTM-return.pt\")\n",
    "plt.plot(record_period * np.arange(len(info[\"return\"])), info[\"return\"], label=\"BootstrappedDQN-LSTM\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MambaConfig(input_dim=101, n_layers=2, num_mamba_layers=1, d_state=16, expand=2, dt_rank=16, d_conv=4, pad_vocab_size_multiple=1, conv_bias=True, bias=False, tie_embeddings=False, use_minimal=False, d_model=256, state_dim=256, pscan=True, dt_min=0.001, dt_max=0.1, dt_init='random', dt_scale=1.0)\n",
      "episode 5, step 100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 10, step 200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 15, step 300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 20, step 400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 25, step 500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 30, step 600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 35, step 700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 40, step 800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 45, step 900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 50, step 1000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 55, step 1100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 60, step 1200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 65, step 1300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 70, step 1400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 75, step 1500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 80, step 1600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 85, step 1700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 90, step 1800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 95, step 1900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 100, step 2000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 105, step 2100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 110, step 2200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 115, step 2300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 120, step 2400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 125, step 2500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 130, step 2600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 135, step 2700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 140, step 2800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 145, step 2900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 150, step 3000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 155, step 3100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 160, step 3200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 165, step 3300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 170, step 3400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 175, step 3500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 180, step 3600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 185, step 3700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 190, step 3800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 195, step 3900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 200, step 4000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 205, step 4100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 210, step 4200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 215, step 4300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 220, step 4400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 225, step 4500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 230, step 4600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 235, step 4700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 240, step 4800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 245, step 4900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 250, step 5000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 255, step 5100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 260, step 5200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 265, step 5300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 270, step 5400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 275, step 5500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 280, step 5600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 285, step 5700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 290, step 5800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 295, step 5900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 300, step 6000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 305, step 6100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 310, step 6200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 315, step 6300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 320, step 6400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 325, step 6500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 330, step 6600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 335, step 6700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 340, step 6800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 345, step 6900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 350, step 7000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 355, step 7100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 360, step 7200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 365, step 7300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 370, step 7400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 375, step 7500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 380, step 7600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 385, step 7700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 390, step 7800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 395, step 7900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 400, step 8000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 405, step 8100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 410, step 8200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 415, step 8300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 420, step 8400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 425, step 8500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 430, step 8600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 435, step 8700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 440, step 8800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 445, step 8900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 450, step 9000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 455, step 9100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 460, step 9200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 465, step 9300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 470, step 9400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 475, step 9500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 480, step 9600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 485, step 9700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 490, step 9800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 495, step 9900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 500, step 10000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 505, step 10100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 510, step 10200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 515, step 10300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 520, step 10400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 525, step 10500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 530, step 10600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 535, step 10700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 540, step 10800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 545, step 10900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 550, step 11000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 555, step 11100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 560, step 11200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 565, step 11300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 570, step 11400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 575, step 11500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 580, step 11600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 585, step 11700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 590, step 11800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 595, step 11900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 600, step 12000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 605, step 12100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 610, step 12200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 615, step 12300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 620, step 12400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 625, step 12500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 630, step 12600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 635, step 12700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 640, step 12800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 645, step 12900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 650, step 13000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 655, step 13100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 660, step 13200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 665, step 13300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 670, step 13400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 675, step 13500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 680, step 13600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 685, step 13700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 690, step 13800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 695, step 13900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 700, step 14000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 705, step 14100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 710, step 14200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 715, step 14300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 720, step 14400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 725, step 14500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 730, step 14600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 735, step 14700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 740, step 14800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 745, step 14900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 750, step 15000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 755, step 15100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 760, step 15200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 765, step 15300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 770, step 15400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 775, step 15500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 780, step 15600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 785, step 15700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 790, step 15800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 795, step 15900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 800, step 16000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 805, step 16100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 810, step 16200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 815, step 16300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 820, step 16400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 825, step 16500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 830, step 16600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 835, step 16700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 840, step 16800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 845, step 16900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 850, step 17000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 855, step 17100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 860, step 17200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 865, step 17300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 870, step 17400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 875, step 17500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 880, step 17600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 885, step 17700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 890, step 17800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 895, step 17900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 900, step 18000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 905, step 18100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 910, step 18200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 915, step 18300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 920, step 18400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 925, step 18500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 930, step 18600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 935, step 18700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 940, step 18800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 945, step 18900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 950, step 19000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 955, step 19100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 960, step 19200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 965, step 19300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 970, step 19400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 975, step 19500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 980, step 19600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 985, step 19700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 990, step 19800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 995, step 19900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1000, step 20000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1005, step 20100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1010, step 20200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1015, step 20300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1020, step 20400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1025, step 20500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1030, step 20600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1035, step 20700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1040, step 20800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1045, step 20900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1050, step 21000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1055, step 21100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1060, step 21200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1065, step 21300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1070, step 21400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1075, step 21500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1080, step 21600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1085, step 21700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1090, step 21800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1095, step 21900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1100, step 22000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1105, step 22100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1110, step 22200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1115, step 22300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1120, step 22400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1125, step 22500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1130, step 22600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1135, step 22700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1140, step 22800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1145, step 22900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1150, step 23000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1155, step 23100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 1160, step 23200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1165, step 23300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1170, step 23400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1175, step 23500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1180, step 23600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1185, step 23700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1190, step 23800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1195, step 23900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1200, step 24000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1205, step 24100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1210, step 24200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1215, step 24300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1220, step 24400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1225, step 24500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1230, step 24600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1235, step 24700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1240, step 24800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1245, step 24900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1250, step 25000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1255, step 25100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1260, step 25200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1265, step 25300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1270, step 25400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1275, step 25500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1280, step 25600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1285, step 25700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1290, step 25800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1295, step 25900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1300, step 26000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1305, step 26100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1310, step 26200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1315, step 26300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1320, step 26400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1325, step 26500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1330, step 26600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1335, step 26700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1340, step 26800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1345, step 26900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1350, step 27000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1355, step 27100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1360, step 27200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1365, step 27300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1370, step 27400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1375, step 27500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1380, step 27600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1385, step 27700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1390, step 27800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1395, step 27900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1400, step 28000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1405, step 28100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1410, step 28200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1415, step 28300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1420, step 28400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1425, step 28500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1430, step 28600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1435, step 28700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1440, step 28800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1445, step 28900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1450, step 29000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1455, step 29100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1460, step 29200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1465, step 29300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1470, step 29400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1475, step 29500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1480, step 29600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1485, step 29700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1490, step 29800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 1495, step 29900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1500, step 30000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1505, step 30100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1510, step 30200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1515, step 30300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1520, step 30400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1525, step 30500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1530, step 30600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1535, step 30700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1540, step 30800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1545, step 30900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1550, step 31000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1555, step 31100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1560, step 31200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1565, step 31300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1570, step 31400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1575, step 31500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1580, step 31600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1585, step 31700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1590, step 31800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1595, step 31900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1600, step 32000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1605, step 32100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1610, step 32200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1615, step 32300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1620, step 32400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1625, step 32500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1630, step 32600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1635, step 32700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1640, step 32800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1645, step 32900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1650, step 33000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1655, step 33100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1660, step 33200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1665, step 33300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1670, step 33400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1675, step 33500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1680, step 33600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1685, step 33700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1690, step 33800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1695, step 33900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1700, step 34000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1705, step 34100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1710, step 34200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1715, step 34300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1720, step 34400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1725, step 34500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1730, step 34600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1735, step 34700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1740, step 34800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1745, step 34900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1750, step 35000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1755, step 35100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1760, step 35200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1765, step 35300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1770, step 35400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1775, step 35500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1780, step 35600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1785, step 35700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1790, step 35800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1795, step 35900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1800, step 36000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 1805, step 36100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1810, step 36200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1815, step 36300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1820, step 36400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1825, step 36500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1830, step 36600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1835, step 36700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1840, step 36800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1845, step 36900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1850, step 37000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 1855, step 37100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1860, step 37200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1865, step 37300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1870, step 37400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1875, step 37500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1880, step 37600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1885, step 37700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1890, step 37800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1895, step 37900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1900, step 38000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1905, step 38100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1910, step 38200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1915, step 38300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1920, step 38400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1925, step 38500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1930, step 38600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1935, step 38700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1940, step 38800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1945, step 38900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1950, step 39000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1955, step 39100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 1960, step 39200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1965, step 39300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1970, step 39400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 1975, step 39500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 1980, step 39600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1985, step 39700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1990, step 39800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 1995, step 39900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2000, step 40000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2005, step 40100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2010, step 40200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2015, step 40300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2020, step 40400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2025, step 40500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2030, step 40600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2035, step 40700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2040, step 40800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2045, step 40900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2050, step 41000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2055, step 41100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2060, step 41200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2065, step 41300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2070, step 41400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2075, step 41500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2080, step 41600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2085, step 41700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2090, step 41800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2095, step 41900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2100, step 42000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2105, step 42100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2110, step 42200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2115, step 42300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2120, step 42400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2125, step 42500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2130, step 42600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2135, step 42700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2140, step 42800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2145, step 42900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2150, step 43000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2155, step 43100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2160, step 43200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2165, step 43300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2170, step 43400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2175, step 43500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2180, step 43600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2185, step 43700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2190, step 43800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2195, step 43900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2200, step 44000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2205, step 44100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2210, step 44200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2215, step 44300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2220, step 44400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2225, step 44500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2230, step 44600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2235, step 44700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2240, step 44800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 2245, step 44900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2250, step 45000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2255, step 45100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2260, step 45200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2265, step 45300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2270, step 45400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2275, step 45500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2280, step 45600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2285, step 45700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2290, step 45800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2295, step 45900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2300, step 46000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2305, step 46100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2310, step 46200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2315, step 46300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2320, step 46400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2325, step 46500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2330, step 46600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2335, step 46700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2340, step 46800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2345, step 46900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2350, step 47000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2355, step 47100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2360, step 47200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2365, step 47300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2370, step 47400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2375, step 47500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2380, step 47600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2385, step 47700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2390, step 47800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2395, step 47900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2400, step 48000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2405, step 48100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2410, step 48200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2415, step 48300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2420, step 48400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2425, step 48500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2430, step 48600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2435, step 48700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2440, step 48800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2445, step 48900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2450, step 49000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 2455, step 49100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2460, step 49200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2465, step 49300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2470, step 49400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2475, step 49500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2480, step 49600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2485, step 49700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2490, step 49800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2495, step 49900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2500, step 50000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2505, step 50100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2510, step 50200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2515, step 50300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2520, step 50400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2525, step 50500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2530, step 50600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2535, step 50700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2540, step 50800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2545, step 50900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2550, step 51000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2555, step 51100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2560, step 51200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2565, step 51300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2570, step 51400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2575, step 51500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2580, step 51600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2585, step 51700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2590, step 51800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2595, step 51900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2600, step 52000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2605, step 52100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2610, step 52200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2615, step 52300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2620, step 52400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2625, step 52500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2630, step 52600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2635, step 52700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2640, step 52800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2645, step 52900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2650, step 53000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2655, step 53100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2660, step 53200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2665, step 53300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2670, step 53400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2675, step 53500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2680, step 53600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2685, step 53700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2690, step 53800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2695, step 53900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2700, step 54000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2705, step 54100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2710, step 54200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2715, step 54300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2720, step 54400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2725, step 54500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2730, step 54600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2735, step 54700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2740, step 54800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2745, step 54900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2750, step 55000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2755, step 55100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2760, step 55200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2765, step 55300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2770, step 55400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2775, step 55500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2780, step 55600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2785, step 55700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2790, step 55800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2795, step 55900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2800, step 56000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2805, step 56100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2810, step 56200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2815, step 56300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2820, step 56400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2825, step 56500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2830, step 56600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2835, step 56700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2840, step 56800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2845, step 56900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2850, step 57000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2855, step 57100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2860, step 57200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2865, step 57300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2870, step 57400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2875, step 57500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2880, step 57600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2885, step 57700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 2890, step 57800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2895, step 57900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2900, step 58000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2905, step 58100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2910, step 58200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2915, step 58300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 2920, step 58400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2925, step 58500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2930, step 58600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2935, step 58700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 2940, step 58800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2945, step 58900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2950, step 59000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2955, step 59100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2960, step 59200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2965, step 59300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 2970, step 59400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2975, step 59500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2980, step 59600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 2985, step 59700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2990, step 59800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 2995, step 59900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3000, step 60000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3005, step 60100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3010, step 60200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3015, step 60300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3020, step 60400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3025, step 60500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3030, step 60600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3035, step 60700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3040, step 60800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3045, step 60900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3050, step 61000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3055, step 61100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3060, step 61200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3065, step 61300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3070, step 61400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3075, step 61500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3080, step 61600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3085, step 61700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3090, step 61800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3095, step 61900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3100, step 62000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3105, step 62100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3110, step 62200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3115, step 62300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3120, step 62400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3125, step 62500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3130, step 62600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3135, step 62700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3140, step 62800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3145, step 62900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3150, step 63000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3155, step 63100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3160, step 63200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3165, step 63300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3170, step 63400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3175, step 63500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3180, step 63600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3185, step 63700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3190, step 63800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3195, step 63900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3200, step 64000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3205, step 64100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3210, step 64200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3215, step 64300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3220, step 64400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3225, step 64500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3230, step 64600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3235, step 64700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3240, step 64800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3245, step 64900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3250, step 65000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3255, step 65100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3260, step 65200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3265, step 65300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3270, step 65400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3275, step 65500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3280, step 65600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3285, step 65700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3290, step 65800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3295, step 65900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3300, step 66000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3305, step 66100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3310, step 66200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3315, step 66300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3320, step 66400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3325, step 66500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3330, step 66600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3335, step 66700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3340, step 66800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3345, step 66900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3350, step 67000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3355, step 67100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3360, step 67200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3365, step 67300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3370, step 67400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3375, step 67500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3380, step 67600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3385, step 67700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3390, step 67800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3395, step 67900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3400, step 68000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3405, step 68100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3410, step 68200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3415, step 68300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3420, step 68400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3425, step 68500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3430, step 68600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3435, step 68700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3440, step 68800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3445, step 68900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3450, step 69000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3455, step 69100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3460, step 69200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3465, step 69300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3470, step 69400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3475, step 69500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3480, step 69600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3485, step 69700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3490, step 69800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3495, step 69900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3500, step 70000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3505, step 70100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3510, step 70200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3515, step 70300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3520, step 70400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3525, step 70500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3530, step 70600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3535, step 70700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3540, step 70800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3545, step 70900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3550, step 71000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3555, step 71100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3560, step 71200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3565, step 71300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3570, step 71400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3575, step 71500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3580, step 71600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3585, step 71700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3590, step 71800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3595, step 71900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3600, step 72000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3605, step 72100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3610, step 72200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3615, step 72300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3620, step 72400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3625, step 72500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3630, step 72600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3635, step 72700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3640, step 72800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3645, step 72900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3650, step 73000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3655, step 73100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3660, step 73200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3665, step 73300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3670, step 73400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3675, step 73500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3680, step 73600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3685, step 73700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3690, step 73800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3695, step 73900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3700, step 74000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3705, step 74100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3710, step 74200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3715, step 74300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3720, step 74400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3725, step 74500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3730, step 74600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3735, step 74700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3740, step 74800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3745, step 74900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3750, step 75000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3755, step 75100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3760, step 75200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3765, step 75300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3770, step 75400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3775, step 75500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3780, step 75600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3785, step 75700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3790, step 75800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3795, step 75900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3800, step 76000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3805, step 76100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3810, step 76200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3815, step 76300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3820, step 76400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3825, step 76500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3830, step 76600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3835, step 76700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3840, step 76800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3845, step 76900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3850, step 77000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3855, step 77100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3860, step 77200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3865, step 77300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 3870, step 77400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3875, step 77500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3880, step 77600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3885, step 77700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3890, step 77800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 3895, step 77900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3900, step 78000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3905, step 78100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3910, step 78200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 3915, step 78300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3920, step 78400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3925, step 78500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3930, step 78600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3935, step 78700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 3940, step 78800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3945, step 78900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3950, step 79000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3955, step 79100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 3960, step 79200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3965, step 79300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3970, step 79400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3975, step 79500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 3980, step 79600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3985, step 79700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3990, step 79800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 3995, step 79900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4000, step 80000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4005, step 80100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4010, step 80200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4015, step 80300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4020, step 80400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4025, step 80500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4030, step 80600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4035, step 80700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4040, step 80800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4045, step 80900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4050, step 81000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4055, step 81100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4060, step 81200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4065, step 81300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4070, step 81400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4075, step 81500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4080, step 81600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4085, step 81700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4090, step 81800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4095, step 81900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4100, step 82000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4105, step 82100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4110, step 82200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4115, step 82300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4120, step 82400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4125, step 82500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4130, step 82600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4135, step 82700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4140, step 82800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4145, step 82900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4150, step 83000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4155, step 83100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4160, step 83200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4165, step 83300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4170, step 83400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4175, step 83500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4180, step 83600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4185, step 83700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4190, step 83800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4195, step 83900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4200, step 84000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4205, step 84100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4210, step 84200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4215, step 84300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4220, step 84400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4225, step 84500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4230, step 84600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4235, step 84700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4240, step 84800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4245, step 84900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4250, step 85000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4255, step 85100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4260, step 85200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4265, step 85300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4270, step 85400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4275, step 85500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4280, step 85600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4285, step 85700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4290, step 85800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4295, step 85900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4300, step 86000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4305, step 86100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4310, step 86200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4315, step 86300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4320, step 86400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4325, step 86500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4330, step 86600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4335, step 86700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4340, step 86800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 4345, step 86900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4350, step 87000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4355, step 87100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 4360, step 87200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4365, step 87300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4370, step 87400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4375, step 87500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4380, step 87600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4385, step 87700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4390, step 87800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4395, step 87900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4400, step 88000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4405, step 88100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4410, step 88200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4415, step 88300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4420, step 88400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4425, step 88500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4430, step 88600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4435, step 88700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4440, step 88800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4445, step 88900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 7.0\n",
      "episode 4450, step 89000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4455, step 89100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4460, step 89200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4465, step 89300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4470, step 89400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4475, step 89500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4480, step 89600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4485, step 89700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4490, step 89800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4495, step 89900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4500, step 90000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4505, step 90100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4510, step 90200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4515, step 90300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4520, step 90400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4525, step 90500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4530, step 90600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4535, step 90700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4540, step 90800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4545, step 90900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4550, step 91000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4555, step 91100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4560, step 91200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4565, step 91300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4570, step 91400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4575, step 91500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4580, step 91600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4585, step 91700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4590, step 91800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4595, step 91900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4600, step 92000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4605, step 92100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4610, step 92200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4615, step 92300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4620, step 92400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4625, step 92500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4630, step 92600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4635, step 92700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4640, step 92800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4645, step 92900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4650, step 93000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4655, step 93100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4660, step 93200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4665, step 93300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4670, step 93400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4675, step 93500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4680, step 93600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4685, step 93700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4690, step 93800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4695, step 93900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4700, step 94000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4705, step 94100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4710, step 94200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4715, step 94300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4720, step 94400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4725, step 94500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4730, step 94600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4735, step 94700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4740, step 94800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4745, step 94900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4750, step 95000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4755, step 95100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4760, step 95200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4765, step 95300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4770, step 95400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4775, step 95500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4780, step 95600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4785, step 95700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4790, step 95800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4795, step 95900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4800, step 96000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4805, step 96100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4810, step 96200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 0.0\n",
      "episode 4815, step 96300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4820, step 96400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 6.0\n",
      "episode 4825, step 96500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4830, step 96600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4835, step 96700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4840, step 96800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4845, step 96900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4850, step 97000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4855, step 97100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4860, step 97200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4865, step 97300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4870, step 97400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4875, step 97500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 5.0\n",
      "episode 4880, step 97600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4885, step 97700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4890, step 97800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4895, step 97900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4900, step 98000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4905, step 98100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4910, step 98200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4915, step 98300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4920, step 98400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4925, step 98500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 4930, step 98600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4935, step 98700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4940, step 98800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4945, step 98900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4950, step 99000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4955, step 99100, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4960, step 99200, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4965, step 99300, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n",
      "episode 4970, step 99400, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4975, step 99500, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4980, step 99600, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4985, step 99700, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 1.0\n",
      "episode 4990, step 99800, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 4.0\n",
      "episode 4995, step 99900, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 3.0\n",
      "episode 5000, step 100000, agent=PearlAgent with BootstrappedDQN, MambaHistorySummarizationModule(\n",
      "  (mamba): MambaWrapper(\n",
      "    (layers_in): Linear(in_features=101, out_features=256, bias=True)\n",
      "    (layers_mid): ModuleList(\n",
      "      (0-1): 2 x Block(\n",
      "        (mixer): Mamba(\n",
      "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
      "          (act): SiLU()\n",
      "          (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
      "          (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layers_out): ModuleList()\n",
      "  )\n",
      "), BootstrapReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x7fa2a25494b0>\n",
      "return: 2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pearl.history_summarization_modules.mamba_history_summmarization_module import MambaHistorySummarizationModule\n",
    "\n",
    "# Better exploration with BootstrappedDQN-LSTM\n",
    "\n",
    "agent = PearlAgent(\n",
    "    policy_learner=BootstrappedDQN(\n",
    "        q_ensemble_network=EnsembleQValueNetwork(\n",
    "            state_dim=256,\n",
    "            action_dim=100,\n",
    "            ensemble_size=10,\n",
    "            output_dim=1,\n",
    "            hidden_dims=[64, 64],\n",
    "            prior_scale=0.3,\n",
    "        ),\n",
    "        action_space=action_space,\n",
    "        training_rounds=50,\n",
    "        action_representation_module=action_representation_module,\n",
    "    ),\n",
    "    history_summarization_module=MambaHistorySummarizationModule(\n",
    "        observation_dim=1,\n",
    "        action_dim=100,\n",
    "        hidden_dim=256,\n",
    "        state_dim=256,\n",
    "        history_length=8,\n",
    "        parallel_scan=True,\n",
    "    ),\n",
    "    replay_buffer=BootstrapReplayBuffer(100_000, 1.0, 10),\n",
    "    device_id=-1,\n",
    ")\n",
    "\n",
    "info = online_learning(\n",
    "    agent=agent,\n",
    "    env=env,\n",
    "    number_of_steps=number_of_steps,\n",
    "    print_every_x_steps=100,\n",
    "    record_period=record_period,\n",
    "    learn_after_episode=True,\n",
    ")\n",
    "torch.save(info[\"return\"], \"BootstrappedDQN-LSTM-return.pt\")\n",
    "plt.plot(record_period * np.arange(len(info[\"return\"])), info[\"return\"], label=\"BootstrappedDQN-LSTM\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T19:15:32.549629100Z",
     "start_time": "2024-01-19T17:06:41.983661900Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this example, we illustrated Pearl's capability of dealing with dynamic action space, standard policy learning, history summarization and intelligent exploration, all in a single agent. By running the code above, you should be able to get agent performance results similar to the figure shown in pearl/tutorials/single_item_recommender_system_example/dqn+lstm+deep_explore.png.\n"
   ]
  }
 ],
 "metadata": {
  "custom": {
   "cells": [],
   "metadata": {
    "custom": {
     "cells": [],
     "metadata": {
      "accelerator": "GPU",
      "colab": {
       "gpuType": "T4",
       "include_colab_link": true,
       "provenance": []
      },
      "fileHeader": "",
      "fileUid": "4316417e-7688-45f2-a94f-24148bfc425e",
      "isAdHoc": false,
      "kernelspec": {
       "display_name": "pearl (local)",
       "language": "python",
       "name": "pearl_local"
      },
      "language_info": {
       "name": "python"
      }
     },
     "nbformat": 4,
     "nbformat_minor": 2
    },
    "fileHeader": "",
    "fileUid": "1158a851-91bb-437e-a391-aba92448f600",
    "indentAmount": 2,
    "isAdHoc": false,
    "language_info": {
     "name": "plaintext"
    }
   },
   "nbformat": 4,
   "nbformat_minor": 2
  },
  "indentAmount": 2,
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
